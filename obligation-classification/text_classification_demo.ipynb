{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0]\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])) #prints first line of the first data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 89 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 86580)\t1\n",
      "  (0, 128420)\t1\n",
      "  (0, 35983)\t1\n",
      "  (0, 35187)\t1\n",
      "  (0, 66098)\t1\n",
      "  (0, 114428)\t1\n",
      "  (0, 78955)\t1\n",
      "  (0, 94362)\t1\n",
      "  (0, 76722)\t1\n",
      "  (0, 57308)\t1\n",
      "  (0, 62221)\t1\n",
      "  (0, 128402)\t2\n",
      "  (0, 67156)\t1\n",
      "  (0, 123989)\t1\n",
      "  (0, 90252)\t1\n",
      "  (0, 63363)\t1\n",
      "  (0, 78784)\t1\n",
      "  (0, 96144)\t1\n",
      "  (0, 128026)\t1\n",
      "  (0, 109271)\t1\n",
      "  (0, 51730)\t1\n",
      "  (0, 86001)\t1\n",
      "  (0, 83256)\t1\n",
      "  (0, 113986)\t1\n",
      "  (0, 37565)\t1\n",
      "  :\t:\n",
      "  (0, 4605)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 92081)\t1\n",
      "  (0, 40998)\t1\n",
      "  (0, 79666)\t1\n",
      "  (0, 89362)\t3\n",
      "  (0, 118983)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 98949)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 87620)\t1\n",
      "  (0, 114731)\t5\n",
      "  (0, 68532)\t3\n",
      "  (0, 37780)\t5\n",
      "  (0, 123984)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 114688)\t1\n",
      "  (0, 85354)\t1\n",
      "  (0, 124031)\t2\n",
      "  (0, 50527)\t2\n",
      "  (0, 118280)\t2\n",
      "  (0, 123162)\t2\n",
      "  (0, 75358)\t2\n",
      "  (0, 56979)\t3\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ddbcb3c7df4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Clients/Khaleeque/DataSciencePractise/venv/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    247\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "len(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 130107)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 86580)\t1\n",
      "  (0, 128420)\t1\n",
      "  (0, 35983)\t1\n",
      "  (0, 35187)\t1\n",
      "  (0, 66098)\t1\n",
      "  (0, 114428)\t1\n",
      "  (0, 78955)\t1\n",
      "  (0, 94362)\t1\n",
      "  (0, 76722)\t1\n",
      "  (0, 57308)\t1\n",
      "  (0, 62221)\t1\n",
      "  (0, 128402)\t2\n",
      "  (0, 67156)\t1\n",
      "  (0, 123989)\t1\n",
      "  (0, 90252)\t1\n",
      "  (0, 63363)\t1\n",
      "  (0, 78784)\t1\n",
      "  (0, 96144)\t1\n",
      "  (0, 128026)\t1\n",
      "  (0, 109271)\t1\n",
      "  (0, 51730)\t1\n",
      "  (0, 86001)\t1\n",
      "  (0, 83256)\t1\n",
      "  (0, 113986)\t1\n",
      "  (0, 37565)\t1\n",
      "  :\t:\n",
      "  (0, 4605)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 92081)\t1\n",
      "  (0, 40998)\t1\n",
      "  (0, 79666)\t1\n",
      "  (0, 89362)\t3\n",
      "  (0, 118983)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 98949)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 87620)\t1\n",
      "  (0, 114731)\t5\n",
      "  (0, 68532)\t3\n",
      "  (0, 37780)\t5\n",
      "  (0, 123984)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 114688)\t1\n",
      "  (0, 85354)\t1\n",
      "  (0, 124031)\t2\n",
      "  (0, 50527)\t2\n",
      "  (0, 118280)\t2\n",
      "  (0, 123162)\t2\n",
      "  (0, 75358)\t2\n",
      "  (0, 56979)\t3\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 'From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n'\n 'From: Rick Miller <rick@ee.uwm.edu>\\nSubject: X-Face?\\nOrganization: Just me.\\nLines: 17\\nDistribution: world\\nNNTP-Posting-Host: 129.89.2.33\\nSummary: Go ahead... swamp me.  <EEP!>\\n\\nI\\'m not familiar at all with the format of these \"X-Face:\" thingies, but\\nafter seeing them in some folks\\' headers, I\\'ve *got* to *see* them (and\\nmaybe make one of my own)!\\n\\nI\\'ve got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\")\\nand I\\'ve managed to compile [un]compface too... but now that I\\'m *looking*\\nfor them, I can\\'t seem to find any X-Face:\\'s in anyones news headers!  :-(\\n\\nCould you, would you, please send me your \"X-Face:\" header?\\n\\nI *know* I\\'ll probably get a little swamped, but I can handle it.\\n\\n\\t...I hope.\\n\\nRick Miller  <rick@ee.uwm.edu> | <ricxjo@discus.mil.wi.us>   Ricxjo Muelisto\\nSend a postcard, get one back! | Enposxtigu bildkarton kaj vi ricevos alion!\\n          RICK MILLER // 16203 WOODS // MUSKEGO, WIS. 53150 // USA\\n'\n 'From: mathew <mathew@mantis.co.uk>\\nSubject: Re: STRONG & weak Atheism\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.02\\nLines: 9\\n\\nacooper@mac.cc.macalstr.edu (Turin Turambar, ME Department of Utter Misery) writes:\\n> Did that FAQ ever got modified to re-define strong atheists as not those who\\n> assert the nonexistence of God, but as those who assert that they BELIEVE in \\n> the nonexistence of God?\\n\\nIn a word, yes.\\n\\n\\nmathew\\n'\n ...,\n 'From: hhenderson@vax.clarku.edu\\nSubject: RE: Game Length (was Re: Braves Update!!\\nOrganization: Clark University\\nLines: 31\\n\\nI sent a version of this post out a while ago, but it was swallowed by\\nthe void.  My apologies if anyone ends up receiving it.\\n\\nSherri Nichols writes:\\n\\n>In article <22APR93.04131972@vax.clarku.edu> hhenderson@vax.clarku.edu writes:\\n>>snichols@adobe.com (Sherri Nichols) writes:\\n>>\\n>>>I just don\\'t\\n>>>happen to think that the 11-15 minutes added to the length of games over\\n>>>the last 10 years has added anything interesting.\\n>>\\n>>How would you quantify that?  I suppose an easy way would be to look at\\n>>attendance figures.  Anyone got the numbers?\\n>\\n>Attendance figures aren\\'t going to quantify anything about my personal\\n>opinion, which the above is clearly stated as.  Add \"to me\" to the end of\\n>my sentence, if you\\'re confused about what I meant.\\n\\nOh no, I wasn\\'t confused -- I understood that it was your personal\\nopinion.  But I thought we were discussing the need to shorten\\ngames.  The arguments which declare this need seem to hinge on\\nthe assertion that long games bore people and otherwise discourage\\nthem from going to the ballpark.  I\\'d like to see if the increased\\nlength of games has negatively affected attendance.  If it has, then\\nthere *is* a problem, and something should be done about it.  If it\\nhasn\\'t, then there *isn\\'t* a problem, and there\\'s no need to monkey\\nwith things as they are.\\n\\nHeather\\nHHENDERSON@vax.clarku.edu\\n'\n \"From: b859zam@utarlg.uta.edu \\nSubject: INTEL CHMOS 8086/8088 DESIGN KIT\\nNews-Software: VAX/VMS VNEWS 1.41    \\nNntp-Posting-Host: utarlg.uta.edu\\nOrganization: The University of Texas at Arlington\\nLines: 33\\n\\nI have this kit which includes the following :\\n\\n1)\\t82c84a/82c84a-5\\n\\tCHMOS CLOCK GENERATOR AND DRIVER\\n\\tFOR 8086,80C88 PROCESSORS\\n2)\\t27C64/87C64\\n\\t64K(8Kx8) CHMOS UV ERASABLE PROM\\n3)\\t51C259L\\n\\tLOW POWER 64K x 4\\n\\tCHMOS DYNAMIC RAM\\n4)\\t82C59A-2\\n\\tCHMOS PROGRAMMABLE INTERRUPT CONTROLLER\\n5)\\t82C88\\n\\tCHMOS BUS CONTROLLER\\n\\tFRO 80C86,80C88 PROCESSORS\\n6)\\t80C88/80C88-2\\n\\t8-BIT CHMOS MICROPROCESSOR\\n7)\\t82C55A\\n\\tCHMOS PROGRAMMABLE PERIPHERAL INTERFACE\\n8)\\t82C54\\n\\tCHMOS PROGRAMMABLE INTERVAL TIMER\\n9)\\t82C08\\n\\tCHMOS DYNAMIC RAM CONTROLLER\\n\\nAll these are chips with complete manual in a box. I don't know whether they\\nstill work or not, and I don't really know what they are. \\n\\nSo this is mainly for those who knows what this is and have use of it \\n(probably EE stuff since this used to belong to a EE student)\\n\\nAnyone interested, please make me an offer.\\n\\nJonina\\n\"\n 'From: adamsj@gtewd.mtv.gtegsc.com\\nSubject: Re: Homosexuality issues in Christianity\\nReply-To: adamsj@gtewd.mtv.gtegsc.com\\nOrganization: GTE Govt. Systems, Electronics Def. Div.\\nLines: 18\\n\\nIn article <May.13.02.29.39.1993.1505@geneva.rutgers.edu>, revdak@netcom.com (D. Andrew Kille) writes:\\n> Of course the whole issue is one of discernment.  It may be that Satan\\n> is trying to convince us that we know more than God.  Or it may be that\\n> God is trying (as God did with Peter) to teach us something we don\\'t\\n> know- that \"God shows no partiality, but in every nation anyone who fears\\n> him and does what is right is acceptable to him.\" (Acts 10:34-35).\\n> \\n> revdak@netcom.com\\n\\nFine, but one of the points of this entire discussion is that \"we\"\\n(conservative, reformed christians - this could start an argument...\\nBut isn\\'t this idea that homosexuality is ok fairly \"new\" [this\\ncentury] ? Is there any support for this being a viable viewpoint\\nbefore this century? I don\\'t know.) don\\'t believe that homosexuality\\nis \"acceptable to Him\". So your scripture quotation doesn\\'t work for\\n\"us\".\\n\\n-jeff adams-\\n'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7c5b03fd016e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtwenty_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwenty_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtwenty_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Clients/Khaleeque/DataSciencePractise/venv/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Clients/Khaleeque/DataSciencePractise/venv/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[1;32m    726\u001b[0m                 self.class_log_prior_)\n",
      "\u001b[0;32m~/Clients/Khaleeque/DataSciencePractise/venv/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 'From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n'\n 'From: Rick Miller <rick@ee.uwm.edu>\\nSubject: X-Face?\\nOrganization: Just me.\\nLines: 17\\nDistribution: world\\nNNTP-Posting-Host: 129.89.2.33\\nSummary: Go ahead... swamp me.  <EEP!>\\n\\nI\\'m not familiar at all with the format of these \"X-Face:\" thingies, but\\nafter seeing them in some folks\\' headers, I\\'ve *got* to *see* them (and\\nmaybe make one of my own)!\\n\\nI\\'ve got \"dpg-view\" on my Linux box (which displays \"uncompressed X-Faces\")\\nand I\\'ve managed to compile [un]compface too... but now that I\\'m *looking*\\nfor them, I can\\'t seem to find any X-Face:\\'s in anyones news headers!  :-(\\n\\nCould you, would you, please send me your \"X-Face:\" header?\\n\\nI *know* I\\'ll probably get a little swamped, but I can handle it.\\n\\n\\t...I hope.\\n\\nRick Miller  <rick@ee.uwm.edu> | <ricxjo@discus.mil.wi.us>   Ricxjo Muelisto\\nSend a postcard, get one back! | Enposxtigu bildkarton kaj vi ricevos alion!\\n          RICK MILLER // 16203 WOODS // MUSKEGO, WIS. 53150 // USA\\n'\n 'From: mathew <mathew@mantis.co.uk>\\nSubject: Re: STRONG & weak Atheism\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.02\\nLines: 9\\n\\nacooper@mac.cc.macalstr.edu (Turin Turambar, ME Department of Utter Misery) writes:\\n> Did that FAQ ever got modified to re-define strong atheists as not those who\\n> assert the nonexistence of God, but as those who assert that they BELIEVE in \\n> the nonexistence of God?\\n\\nIn a word, yes.\\n\\n\\nmathew\\n'\n ...,\n 'From: hhenderson@vax.clarku.edu\\nSubject: RE: Game Length (was Re: Braves Update!!\\nOrganization: Clark University\\nLines: 31\\n\\nI sent a version of this post out a while ago, but it was swallowed by\\nthe void.  My apologies if anyone ends up receiving it.\\n\\nSherri Nichols writes:\\n\\n>In article <22APR93.04131972@vax.clarku.edu> hhenderson@vax.clarku.edu writes:\\n>>snichols@adobe.com (Sherri Nichols) writes:\\n>>\\n>>>I just don\\'t\\n>>>happen to think that the 11-15 minutes added to the length of games over\\n>>>the last 10 years has added anything interesting.\\n>>\\n>>How would you quantify that?  I suppose an easy way would be to look at\\n>>attendance figures.  Anyone got the numbers?\\n>\\n>Attendance figures aren\\'t going to quantify anything about my personal\\n>opinion, which the above is clearly stated as.  Add \"to me\" to the end of\\n>my sentence, if you\\'re confused about what I meant.\\n\\nOh no, I wasn\\'t confused -- I understood that it was your personal\\nopinion.  But I thought we were discussing the need to shorten\\ngames.  The arguments which declare this need seem to hinge on\\nthe assertion that long games bore people and otherwise discourage\\nthem from going to the ballpark.  I\\'d like to see if the increased\\nlength of games has negatively affected attendance.  If it has, then\\nthere *is* a problem, and something should be done about it.  If it\\nhasn\\'t, then there *isn\\'t* a problem, and there\\'s no need to monkey\\nwith things as they are.\\n\\nHeather\\nHHENDERSON@vax.clarku.edu\\n'\n \"From: b859zam@utarlg.uta.edu \\nSubject: INTEL CHMOS 8086/8088 DESIGN KIT\\nNews-Software: VAX/VMS VNEWS 1.41    \\nNntp-Posting-Host: utarlg.uta.edu\\nOrganization: The University of Texas at Arlington\\nLines: 33\\n\\nI have this kit which includes the following :\\n\\n1)\\t82c84a/82c84a-5\\n\\tCHMOS CLOCK GENERATOR AND DRIVER\\n\\tFOR 8086,80C88 PROCESSORS\\n2)\\t27C64/87C64\\n\\t64K(8Kx8) CHMOS UV ERASABLE PROM\\n3)\\t51C259L\\n\\tLOW POWER 64K x 4\\n\\tCHMOS DYNAMIC RAM\\n4)\\t82C59A-2\\n\\tCHMOS PROGRAMMABLE INTERRUPT CONTROLLER\\n5)\\t82C88\\n\\tCHMOS BUS CONTROLLER\\n\\tFRO 80C86,80C88 PROCESSORS\\n6)\\t80C88/80C88-2\\n\\t8-BIT CHMOS MICROPROCESSOR\\n7)\\t82C55A\\n\\tCHMOS PROGRAMMABLE PERIPHERAL INTERFACE\\n8)\\t82C54\\n\\tCHMOS PROGRAMMABLE INTERVAL TIMER\\n9)\\t82C08\\n\\tCHMOS DYNAMIC RAM CONTROLLER\\n\\nAll these are chips with complete manual in a box. I don't know whether they\\nstill work or not, and I don't really know what they are. \\n\\nSo this is mainly for those who knows what this is and have use of it \\n(probably EE stuff since this used to belong to a EE student)\\n\\nAnyone interested, please make me an offer.\\n\\nJonina\\n\"\n 'From: adamsj@gtewd.mtv.gtegsc.com\\nSubject: Re: Homosexuality issues in Christianity\\nReply-To: adamsj@gtewd.mtv.gtegsc.com\\nOrganization: GTE Govt. Systems, Electronics Def. Div.\\nLines: 18\\n\\nIn article <May.13.02.29.39.1993.1505@geneva.rutgers.edu>, revdak@netcom.com (D. Andrew Kille) writes:\\n> Of course the whole issue is one of discernment.  It may be that Satan\\n> is trying to convince us that we know more than God.  Or it may be that\\n> God is trying (as God did with Peter) to teach us something we don\\'t\\n> know- that \"God shows no partiality, but in every nation anyone who fears\\n> him and does what is right is acceptable to him.\" (Acts 10:34-35).\\n> \\n> revdak@netcom.com\\n\\nFine, but one of the points of this entire discussion is that \"we\"\\n(conservative, reformed christians - this could start an argument...\\nBut isn\\'t this idea that homosexuality is ok fairly \"new\" [this\\ncentury] ? Is there any support for this being a viable viewpoint\\nbefore this century? I don\\'t know.) don\\'t believe that homosexuality\\nis \"acceptable to Him\". So your scripture quotation doesn\\'t work for\\n\"us\".\\n\\n-jeff adams-\\n'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khaleeque.ansari/Clients/Khaleeque/DataSciencePractise/venv/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82381837493361654"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, n_iter=5, random_state=42)),\n",
    " ])\n",
    "_ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90675269577514583"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89791408873961465"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf_svm.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
